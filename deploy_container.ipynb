{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook we will use to find and deploy the most affordable GPU's on the market with the Shadeform API. We limit our search to machines with 1x80GB A100 machines, but that is easily configurable below.\n",
    "\n",
    "This notebook leverages the docker container created under `llm-eval-harness-benchmarking` to run basic huggingface benchmarks for a given huggingface model.\n",
    "\n",
    "It also re-uses code from [find_and_use_gpus.ipynb](link.com) for using the Shadeform API to find available instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexowen/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://api.shadeform.ai/v1/instances\"\n",
    "instance_type_url = base_url + \"/types\"\n",
    "create_url = base_url + \"/create\"\n",
    "headers = {\n",
    "    \"X-API-KEY\": \"wMKxY8d52U3EHmFYnd8qr5y6\", \n",
    "    \"Content-Type\" : \"application/json\"\n",
    "}\n",
    "shade_instance_type = \"A6000\"\n",
    "gpu_type = \"A6000\"\n",
    "num_gpus = 1\n",
    "\n",
    "params = {\n",
    "    'gpu_type' : gpu_type,\n",
    "    'sort' : 'price',\n",
    "    'available' : True,\n",
    "    'num_gpus' : num_gpus\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cheapest A6000 instance with 1 gpu(s) is: {'cloud': 'massedcompute', 'shade_instance_type': 'A6000', 'cloud_instance_type': 'gpu_1x_a6000', 'configuration': {'memory_in_gb': 48, 'storage_in_gb': 256, 'vcpus': 6, 'num_gpus': 1, 'gpu_type': 'A6000', 'interconnect': 'pcie', 'os_options': ['ubuntu22.04_cuda12.2_shade_os'], 'vram_per_gpu_in_gb': 48}, 'memory_in_gb': 48, 'storage_in_gb': 256, 'vcpus': 6, 'num_gpus': 1, 'gpu_type': 'A6000', 'interconnect': 'pcie', 'hourly_price': 57, 'availability': [{'region': 'us-central-2', 'available': True}]}\n"
     ]
    }
   ],
   "source": [
    "response = requests.request(\"GET\", instance_type_url, headers=headers, params=params)\n",
    "instance_types = json.loads(response.text)[\"instance_types\"]\n",
    "best_instance = None\n",
    "region = None\n",
    "if len(instance_types) > 0:\n",
    "    best_instance = instance_types[0]\n",
    "    region = best_instance['availability'][0]['region']\n",
    "    print(f\"The cheapest {gpu_type} instance with {num_gpus} gpu(s) is:\", best_instance)\n",
    "else:\n",
    "    print(f\"No instances of type {gpu_type} instance with {num_gpus} gpu(s) found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "  \"cloud\": best_instance[\"cloud\"],\n",
    "  \"region\": region,\n",
    "  \"shade_instance_type\": shade_instance_type,\n",
    "  \"shade_cloud\": True,\n",
    "  \"name\": \"cool_gpu_server\",\n",
    "  \"launch_configuration\": {\n",
    "    \"type\": \"docker\",\n",
    "    \"docker_configuration\": {\n",
    "      \"image\": \"shadeform/lm-eval-harness\",\n",
    "      \"envs\": [\n",
    "      \t{\n",
    "\t      \t\"name\": \"model\",\n",
    "\t      \t\"value\": \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "      \t},\n",
    "      \t{\n",
    "\t      \t\"name\": \"tasks\",\n",
    "\t      \t\"value\": \"hellaswag\"\n",
    "      \t},\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#request the best instance that is available\n",
    "response = requests.request(\"POST\", create_url, json=payload, headers=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"4e90f11a-e098-4b11-a9fa-ebc381e9bc9a\",\"cloud_assigned_id\":\"c23ad075-9615-49b9-9a89-e8ee743a12b2\"}\n"
     ]
    }
   ],
   "source": [
    "#easy way to visually see if this request worked\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"instances\":[{\"id\":\"4e90f11a-e098-4b11-a9fa-ebc381e9bc9a\",\"cloud\":\"massedcompute\",\"region\":\"us-central-2\",\"shade_instance_type\":\"A6000\",\"cloud_instance_type\":\"gpu_1x_a6000\",\"cloud_assigned_id\":\"c23ad075-9615-49b9-9a89-e8ee743a12b2\",\"shade_cloud\":true,\"name\":\"cool_gpu_server\",\"configuration\":{\"memory_in_gb\":48,\"storage_in_gb\":256,\"vcpus\":6,\"num_gpus\":1,\"gpu_type\":\"A6000\",\"interconnect\":\"pcie\",\"os\":\"ubuntu22.04_cuda12.2_shade_os\",\"vram_per_gpu_in_gb\":48},\"ip\":\"64.247.196.46\",\"ssh_user\":\"shadeform\",\"ssh_port\":22,\"status\":\"active\",\"status_details\":\"Container run started... View docker progress logs by running 'journalctl -u init-script'\",\"cost_estimate\":\"0.0335054514\",\"hourly_price\":57,\"created_at\":\"2024-02-21T18:03:42.911404Z\",\"deleted_at\":null,\"launch_configuration\":{\"type\":\"docker\",\"docker_configuration\":{\"image\":\"shadeform/lm-eval-harness\",\"envs\":[{\"name\":\"tasks\",\"value\":\"hellaswag\"},{\"name\":\"model\",\"value\":\"mistralai/Mistral-7B-Instruct-v0.2\"}]}}}]}\n",
      "Instance is active with IP: 64.247.196.46\n"
     ]
    }
   ],
   "source": [
    "instance_response = requests.request(\"GET\", base_url, headers=headers)\n",
    "\n",
    "print(instance_response.text)\n",
    "instance = json.loads(instance_response.text)[\"instances\"][0]\n",
    "instance_status = instance['status']\n",
    "if instance_status == 'active':\n",
    "    print(f\"Instance is active with IP: {instance['ip']}\")\n",
    "else:\n",
    "    print(f\"Instance isn't yet active: {instance}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
